# @Author: Simon Dahan
# @Last Modified time: 2022-01-12 14:11:23
resolution:
  ico: 6            ## full mesh resolution
  sub_ico: 2        ## patch resolution

data:
  data_path: ./code/cv_utils/data/{}/{}
  task: alzheimer #scan_age # birth_age #adult_age #alzheimer #HCP_age
  configuration: template #template # native
  num_classes: 3
  log_data: False
  log_statistics: False

setup:
  mode: training
  seed: 864
  learning_rate: 0.00000719293780196941 #0.00001
  batch_size: 32 #64
  batch_size_val: 32
  epochs: 250 #1000
  use_gpu: True
  testing: True
  val_epoch: 10
  load_weights: imagenet
  finetuning: False
  architecture: tiny
  add_noise: False
  noise_scale: 0.5
  temperature: 1
  save_ckpt: True
  early_stopping: False
  monitor: metrics/BalancedAccuracy/val
  monitor_mode: max

early_stopping:
  min_delta: 0.05
  patience: 3 # only evaluated every val_epoch
  divergence_threshold: 0.33

weights:
  wandb: # uses current user and project if not explicitly specified
    xtiny: "model-ce5ca_00000:v13"
    tiny: "moritzschueler96/svit/model-ce5ca_00000:best"
    small: "moritzschueler96/svit/model-2677a_00000:latest"
    base: "moritzschueler96/svit/model-2677a_00000:best"
  imagenet:
    tiny: 'vit_tiny_patch16_224' #ViT(dim=192, depth=12, heads=3,mlp_dim=768,dim_head=64)
    small: 'vit_small_patch16_224' #ViT(dim=384, depth=12, heads=6,mlp_dim=1536,dim_head=64)
    base: 'vit_base_patch16_224' #ViT(dim=768, depth=12, heads=12,mlp_dim=3072,dim_head=64)
            
transformer:
  xtiny:
    dim: 96
    depth: 12
    heads: 2
    mlp_dim: 384 # 4*dim according to DeiT
    pool: 'cls'
    dim_head: 64
    dropout: 0.0
    emb_dropout: 0.0
  tiny:
    dim: 192 #192, 384, 768
    depth: 12 #12, 12, 12
    heads: 3 #3, 6, 12
    mlp_dim: 768 #768, 1536, 3072 ## 4*dim according to DeiT
    pool: 'cls'  # or 'mean'
    dim_head: 64 #64
    dropout: 0.20699865730499045 # 0.0
    emb_dropout: 0.15556303467928978 # 0.0
  small:
    dim: 384 #192, 384, 768
    depth: 12 #12, 12, 12
    heads: 6 #3, 6, 12
    mlp_dim: 1536 #768, 1536, 3072 ## 4*dim according to DeiT
    pool: 'cls'  # or 'mean'
    dim_head: 64 #64
    dropout: 0.0
    emb_dropout: 0.0
  base:
    dim: 768 #192, 384, 768
    depth: 12 #12, 12, 12
    heads: 12 #3, 6, 12
    mlp_dim: 3072 #768, 1536, 3072 ## 4*dim according to DeiT
    pool: 'cls'  # or 'mean'
    dim_head: 64 #64
    dropout: 0.0
    emb_dropout: 0.0

optimisation:
  optimiser: SGD # SGD, Adam, AdamW
  weight_decay: 0.03178989086424102 # suitable range: 0.025 to 0.05
  decouple_weight_decay: True
  use_scheduler: False # not used
  scheduler: CosineDecay  # CosineDecay, StepLR, ReduceLROnPlateau
  warmup: False
  nbr_step_warmup: 50

SGD:
  momentum: 0.9
  nesterov: False
  
StepLR:
  stepsize: 1000
  decay: 0.5

CosineDecay:
  T_max: 5000
  eta_min: 0.0001

sub_ico_0:
    num_patches: 20 
    num_vertices: 2145 

sub_ico_1:
    num_patches: 80 
    num_vertices: 561 

sub_ico_2:
    num_patches: 320
    num_vertices: 153 



